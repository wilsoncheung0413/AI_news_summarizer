{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3468ebe-a8d9-401b-850a-b331570c3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12fde7-966f-4123-86b9-9de52203e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai = OpenAI()\n",
    "MODEL = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aaf141-22a2-4ab8-b1e7-eadebdbcfcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c119063-ed37-42f3-b05f-b9f73402dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_NEWS_SITES = [\n",
    "    \"https://the-decoder.com/\",\n",
    "    \"https://venturebeat.com/category/ai/\",\n",
    "    \"https://huggingface.co/blog\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12c18d-b847-4808-a7b8-f6a84924d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsScraper:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        self.articles = []\n",
    "        self.scrape()\n",
    "\n",
    "    def scrape(self):\n",
    "        try:\n",
    "            res = requests.get(self.base_url, headers=headers)\n",
    "            res.encoding = res.apparent_encoding\n",
    "            soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "\n",
    "            anchors = soup.find_all(\"a\", href=True)\n",
    "            links = [a[\"href\"] for a in anchors if a[\"href\"].startswith(\"http\") or a[\"href\"].startswith(\"/\")]\n",
    "            links = list(set(links))[:10]  # Limit to 10 for performance\n",
    "\n",
    "            for link in links:\n",
    "                full_link = link if link.startswith(\"http\") else self.base_url.rstrip(\"/\") + link\n",
    "                try:\n",
    "                    article_res = requests.get(full_link, headers=headers, timeout=5)\n",
    "                    res.encoding = res.apparent_encoding\n",
    "                    article_soup = BeautifulSoup(article_res.content, \"html.parser\")\n",
    "                    title = article_soup.title.string if article_soup.title else \"(No title)\"\n",
    "                    p_tags = article_soup.find_all(\"p\")\n",
    "                    text = \" \".join([p.get_text() for p in p_tags])\n",
    "                    text = text.encode('utf-8', errors='replace').decode('utf-8', errors='replace')\n",
    "                    self.articles.append({\n",
    "                        \"title\": title.strip(),\n",
    "                        \"url\": full_link,\n",
    "                        \"content\": text.strip()[:4000]  # Truncate to 4000 chars to fit model context\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {self.base_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c4003-2511-4b1d-b9e0-1b636ccc827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(article, stream=False):\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant summarizing breaking news in AI. \n",
    "    Give a 3-sentence summary of the following article. Focus on what happened, who was involved, and why it matters.\n",
    "    End it with a recommendation of cool projects I can build, if applicable.\n",
    "    Be snarky and sarcastic!\n",
    "\n",
    "    Title: {article['title']}\n",
    "    Content: {article['content']}\n",
    "    \"\"\"\n",
    "\n",
    "    if stream:\n",
    "        chat_stream = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You summarize recent AI news.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            stream=True\n",
    "        )\n",
    "        response = f\"### [{article['title']}]({article['url']})\\n\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        for chunk in chat_stream:\n",
    "            delta = chunk.choices[0].delta.content or ''\n",
    "            response += delta\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "    else:\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You summarize recent AI news.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            summary = response.choices[0].message.content.strip()\n",
    "            return f\"### [{article['title']}]({article['url']})\\n{summary}\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing article: {e}\")\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af679817-f86e-47c0-b364-bbb50a7ef87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = []\n",
    "for site in AI_NEWS_SITES:\n",
    "    scraper = NewsScraper(site)\n",
    "    all_articles.extend(scraper.articles)\n",
    "\n",
    "for article in all_articles[:5]:\n",
    "    summarize_article(article, stream=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
